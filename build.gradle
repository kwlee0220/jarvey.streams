plugins {
	id 'java-library'
	id 'eclipse'
	id 'com.google.protobuf' version '0.9.4'
	id 'com.github.johnrengelman.shadow' version '7.1.2'
	id 'maven-publish'
}

group = 'etri'
version = '24.01.17'

sourceCompatibility = '11'
targetCompatibility = '11'
[compileJava,compileTestJava]*.options*.encoding = 'UTF-8'

protobuf {
    protoc {
        artifact = "com.google.protobuf:protoc:3.25.2"
    }
    plugins {
        grpc {
            artifact = 'io.grpc:protoc-gen-grpc-java:1.60.1'
        }
    }
    generateProtoTasks {
    	ofSourceSet('main').configureEach {
    		plugins {
            	grpc {}
            }
        }
    }
}

sourceSets {
	main {
		proto {
			srcDirs 'src/main/proto'
		}
		java {
			srcDirs 'build/generated/source/proto/main/grpc'
			srcDirs 'build/generated/source/proto/main/java'
		}
	}
}

repositories {
	mavenLocal()
	maven {
		url "http://repo.osgeo.org/repository/release/"
		allowInsecureProtocol = true
	}
	maven {
		url "https://packages.confluent.io/maven/"
		allowInsecureProtocol = true
	}
	mavenCentral()
}

ext {
	logback_version = '1.5.2'
	guava_version = '32.1.3-jre'
	gson_version = '2.9.0'
	snakeyaml_version = '1.20'
	picocli_version = '3.9.6'
	
	geotools_version = '26.1'
	jts_version = '1.18.2'
	
	kafka_streams_version = '3.5.1'
	avro_version = '1.10.1'
	
	protobuf_java_version='3.24.1'
	kafka_protobuf_serde_version= '2.2.0'
	
	postgresql_version = '42.3.3'
	javalin_version = '4.6.3'
	okhttp_version = '4.10.0'
	
	rxjava_version = '3.1.8'
}

dependencies {
	implementation project(":utils")
	implementation project(":utils.geo")
	
	implementation "com.google.guava:guava:${guava_version}"
	
	// Logback
	testImplementation "ch.qos.logback:logback-classic:${logback_version}"
	
//	implementation "org.apache.logging.log4j:log4j-api:${log4j_version}"
//	implementation "org.apache.logging.log4j:log4j-core:${log4j_version}"
//	implementation "org.apache.logging.log4j:log4j-slf4j-impl:${log4j_version}"
	
	implementation "com.google.code.gson:gson:${gson_version}"
	implementation "org.apache.avro:avro:${avro_version}"
	implementation "org.yaml:snakeyaml:${snakeyaml_version}"
	
	// command line parser
	implementation "info.picocli:picocli:${picocli_version}"
	
	// GeoTools
	implementation	"org.geotools:gt-main:${geotools_version}"
	//api "org.locationtech.jts-core:jts:${jts_version}"
	
	// Kafka Streams
	implementation "org.apache.kafka:kafka-streams:${kafka_streams_version}"
	implementation ('io.confluent:kafka-streams-avro-serde:6.0.1') {
		exclude group: 'org.apache.kafka', module: 'kafka-clients'
	}
	
	// RxJava
	implementation "io.reactivex.rxjava3:rxjava:${rxjava_version}"
	
	// Postgresql
	implementation "org.postgresql:postgresql:${postgresql_version}"
	
	// for remote state store access
	implementation "io.javalin:javalin:${javalin_version}"
	implementation "com.squareup.okhttp3:okhttp:${okhttp_version}"

	implementation "com.google.protobuf:protobuf-java:${protobuf_java_version}"
	implementation "com.github.daniel-shuy:kafka-protobuf-serde:${kafka_protobuf_serde_version}"
	
	implementation fileTree(dir: 'lib', include: '*.jar')
	
	testImplementation group: 'junit', name: 'junit', version: '4.12'
}

shadowJar {
//	classifier 'all'
	
	zip64 true
	mergeServiceFiles()
	
	exclude 'META-INF/*.SF'
	exclude 'META-INF/*.DSA'
	exclude 'META-INF/*.RSA'
}

task sourceJar(type: Jar) {
	from sourceSets.main.allSource
}

task javadocJar(type: Jar) {
	from javadoc.destinationDir
}

// duplication ���� ������
tasks.withType(Copy).all { duplicatesStrategy = DuplicatesStrategy.EXCLUDE }
tasks.withType(Jar) { duplicatesStrategy = DuplicatesStrategy.EXCLUDE }

artifacts {
	archives sourceJar
	archives javadocJar
	archives shadowJar
}

publishing {
	publications {
		marmotClient(MavenPublication) {
			from components.java
			
			artifact sourceJar
			artifact javadocJar
			artifact shadowJar
		}
	}
}

eclipse {
	classpath {
		file {
			withXml {
				def node = it.asNode()
				node.appendNode('classpathentry', [kind: 'output', path: 'build/classes'])
			}
			
			whenMerged { cp ->
				Map entryByPath = cp.entries.groupBy { entry -> entry.path }
				entryByPath.each { key, values ->
					if ( values.size() > 1 ) {
            			def entry = values.first()
            			if ( entry.kind == 'src' ) {
            				entry.includes = []
            				entry.excludes = []
            			}
            			int index = cp.entries.indexOf entry
            			cp.entries.removeAll values
            			cp.entries.add index, entry
					}
				}
				cp.entries.each { entry ->
					if ( entry.kind == 'src' && entry.hasProperty('output') ) {
						if ( entry.path.contains('/test/') ) {
							entry.output = 'build/test_classes'
						}
						else {
							entry.output = 'build/classes'
						}
					}
				}
			}
		}
	}
}
